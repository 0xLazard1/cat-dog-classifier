#!/usr/bin/env python3
"""
API FastAPI pour la classification d'images chats/chiens
VERSION PYTORCH UNIQUEMENT - Optimis√© Apple Silicon M4
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from PIL import Image
import numpy as np
import io
import os
from datetime import datetime
import uvicorn
import pickle
import torch

# Configuration de l'API
app = FastAPI(
    title="API Classification Chats/Chiens - PyTorch M4", 
    version="4.0.0",
    description="Classification d'images avec CNN PyTorch optimis√© Apple Silicon"
)

# Configuration CORS pour React
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Variables globales
model_wrapper = None
model_loaded = False

class PyTorchModelManager:
    """Gestionnaire pour mod√®le PyTorch uniquement"""
    
    def __init__(self):
        self.model = None
        self.model_type = "CNN_PyTorch_M4"
        self.input_shape = (224, 224, 3)
        self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
        
    def load_model(self):
        """Charge le mod√®le PyTorch"""
        model_paths = [
            './best_cnn_model.pkl',
            './models/best_cnn_model.pkl'
        ]
        
        try:
            # Charger le mod√®le PyTorch
            for path in model_paths:
                if os.path.exists(path):
                    try:
                        with open(path, 'rb') as f:
                            data = pickle.load(f)
                        
                        self.model = data['model']
                        print(f"‚úÖ Mod√®le PyTorch charg√© depuis {path}")
                        print(f"üöÄ Device: {self.device}")
                        return True
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è Erreur chargement {path}: {e}")
                        continue
            
            # Si aucun mod√®le trouv√©, cr√©er un mod√®le de test
            print("‚ö†Ô∏è Aucun mod√®le trouv√©, cr√©ation d'un mod√®le PyTorch de test")
            from CNN_Model import CatDogCNN
            pytorch_model = CatDogCNN()
            
            # Cr√©er le wrapper
            class PyTorchModelWrapper:
                def __init__(self, model):
                    self.model = model
                    self.input_shape = (224, 224, 3)
                    self.num_classes = 1
                    
                def predict_proba(self, x):
                    return self.model.predict_proba(x)
            
            self.model = PyTorchModelWrapper(pytorch_model)
            print("üß™ Mod√®le PyTorch de test cr√©√©")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement: {e}")
            return False
    
    def preprocess_image(self, image: Image.Image) -> np.ndarray:
        """Pr√©traite une image pour PyTorch CNN"""
        # Conversion RGB
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # Redimensionner
        image = image.resize((224, 224), Image.Resampling.LANCZOS)
        
        # Convertir en array et normaliser
        image_array = np.array(image, dtype=np.float32) / 255.0
        
        # Ajouter dimension batch: (1, 224, 224, 3)
        return np.expand_dims(image_array, axis=0)
    
    def predict(self, image: Image.Image) -> dict:
        """Fait une pr√©diction avec PyTorch CNN"""
        if not self.model:
            raise ValueError("Mod√®le non charg√©")
        
        # Preprocessing
        image_processed = self.preprocess_image(image)
        
        # Pr√©diction
        try:
            probabilities = self.model.predict_proba(image_processed)
            
            # Extraire la probabilit√©
            if isinstance(probabilities, np.ndarray):
                prob_dog = float(probabilities.flatten()[0])
            else:
                prob_dog = float(probabilities)
            
            # Assurer [0, 1]
            prob_dog = max(0.0, min(1.0, prob_dog))
            prob_cat = 1.0 - prob_dog
            
            # Classification
            predicted_class = "chien" if prob_dog > 0.5 else "chat"
            confidence = prob_dog if predicted_class == "chien" else prob_cat
            
            return {
                "predicted_class": predicted_class,
                "confidence": float(confidence),
                "probabilities": {
                    "chat": float(prob_cat),
                    "chien": float(prob_dog)
                },
                "model_type": self.model_type,
                "device": str(self.device)
            }
            
        except Exception as e:
            raise ValueError(f"Erreur de pr√©diction: {str(e)}")

# Initialiser le gestionnaire
model_manager = PyTorchModelManager()

@app.on_event("startup")
async def startup_event():
    """D√©marrage - charge le mod√®le PyTorch"""
    global model_loaded
    print("üöÄ D√©marrage API PyTorch...")
    print(f"üîß PyTorch version: {torch.__version__}")
    model_loaded = model_manager.load_model()
    if model_loaded:
        print("‚úÖ API PyTorch pr√™te (Apple Silicon optimized)")
    else:
        print("‚ö†Ô∏è API d√©marr√©e avec mod√®le de test")

@app.get("/")
async def root():
    """Endpoint racine"""
    return {
        "message": "üê±üê∂ API Classification Chats/Chiens",
        "version": "4.0.0",
        "model": "CNN PyTorch (Apple Silicon M4)",
        "status": "running",
        "model_loaded": model_loaded,
        "device": str(model_manager.device),
        "pytorch_version": torch.__version__,
        "input_size": "224x224",
        "expected_accuracy": "85-95%"
    }

@app.get("/health")
async def health():
    """√âtat de sant√© de l'API"""
    return {
        "status": "healthy" if model_loaded else "degraded",
        "model_loaded": model_loaded,
        "model_type": model_manager.model_type,
        "device": str(model_manager.device),
        "timestamp": datetime.now().isoformat()
    }

@app.get("/model-info")
async def model_info():
    """Informations d√©taill√©es sur le mod√®le"""
    return {
        "architecture": "CNN PyTorch (5 Conv + 2 Dense)",
        "input_shape": model_manager.input_shape,
        "model_type": model_manager.model_type,
        "device": str(model_manager.device),
        "preprocessing": "Standard normalization",
        "expected_accuracy": "85-95%",
        "optimized_for": "Apple Silicon M4"
    }

@app.post("/predict")
async def predict_image(file: UploadFile = File(...)):
    """Classification d'une image avec PyTorch CNN"""
    
    # V√©rifications
    if not model_manager.model:
        raise HTTPException(status_code=503, detail="Mod√®le non disponible")
    
    if not file.content_type or not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="Le fichier doit √™tre une image")
    
    try:
        # Charger l'image
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        # Pr√©diction
        result = model_manager.predict(image)
        
        # M√©tadonn√©es
        result.update({
            "filename": file.filename,
            "file_size": len(contents),
            "timestamp": datetime.now().isoformat(),
            "api_version": "4.0.0"
        })
        
        return JSONResponse(content=result)
        
    except ValueError as e:
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

if __name__ == "__main__":
    print("üê±üê∂ API Classification PyTorch - Apple Silicon M4")
    print("üì° URL: http://localhost:8000")
    print("üìö Docs: http://localhost:8000/docs")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)